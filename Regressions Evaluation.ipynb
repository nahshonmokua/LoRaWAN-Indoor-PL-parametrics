{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e2080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ecfcdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training samples: 1209643, Test samples: 302411\n",
      "{np.int64(0): np.int64(241929), np.int64(1): np.int64(241929), np.int64(2): np.int64(241929), np.int64(3): np.int64(241928), np.int64(4): np.int64(241928)}\n",
      "\n",
      "Dataset loaded successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Path to the standardized database directory\n",
    "base_path = '../Extended Parametric Regression Files+Plots.'\n",
    "\n",
    "# Load train and test splits\n",
    "df_train = pd.read_csv(f\"{base_path}/train.csv\")\n",
    "df_test = pd.read_csv(f\"{base_path}/test.csv\")\n",
    "\n",
    "# Extract features and targets\n",
    "feature_names = [\n",
    "    'distance', 'frequency', 'c_walls', 'w_walls', 'co2', 'humidity', \n",
    "    'pm25', 'pressure', 'temperature', 'snr'\n",
    "]\n",
    "X_train = df_train[feature_names].values\n",
    "y_train = df_train['PL'].values\n",
    "X_test = df_test[feature_names].values\n",
    "y_test = df_test['PL'].values\n",
    "\n",
    "# (Should we need 'time' for plotting)\n",
    "time_train = df_train['time'].values\n",
    "time_test = df_test['time'].values\n",
    "\n",
    "# Print number of samples in train and test sets\n",
    "print(f\"\\nTraining samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Load 5-fold assignments (array of fold numbers for each train sample)\n",
    "fold_assignments = np.load(f\"{base_path}/train_folds.npy\")\n",
    "\n",
    "# Print fold distribution\n",
    "unique, counts = np.unique(fold_assignments, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "print('\\nDataset loaded successfully!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c90b00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Regression Models Evaluation on Test Set (sorted by RMSE):\n",
      "\n",
      "     Model    RMSE      R2\n",
      "      Poly 7.00687 0.86587\n",
      "     Ridge 8.20975 0.81586\n",
      "  Bayesian 8.20975 0.81586\n",
      "Elasticnet 8.20975 0.81586\n",
      "     Lasso 8.20975 0.81586\n",
      "       Mlr 8.20975 0.81586\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare linearized features and adjusted targets for linear models\n",
    "# Linearization separates the non-linear frequency term and transforms distance term\n",
    "d0 = 1.0\n",
    "\n",
    "# Train\n",
    "log_d_train = np.log10(X_train[:, 0] / d0)\n",
    "offset_train = 20 * np.log10(X_train[:, 1])  # Fixed frequency contribution\n",
    "X_lin_train = np.column_stack((\n",
    "    10 * log_d_train,  # Transformed distance term for path loss exponent\n",
    "    X_train[:, 2:10]   # Remaining linear features\n",
    "))\n",
    "y_train_adj = y_train - offset_train  # Adjust target by subtracting frequency offset\n",
    "\n",
    "# Test\n",
    "log_d_test = np.log10(X_test[:, 0] / d0)\n",
    "offset_test = 20 * np.log10(X_test[:, 1])\n",
    "X_lin_test = np.column_stack((\n",
    "    10 * log_d_test,\n",
    "    X_test[:, 2:10]\n",
    "))\n",
    "y_test_adj = y_test - offset_test\n",
    "\n",
    "# List of model names based on saved files\n",
    "model_names = ['bayesian', 'elasticnet', 'lasso', 'mlr', 'poly', 'ridge']\n",
    "\n",
    "# Directory for models\n",
    "models_dir = 'Models'\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "\n",
    "# Number of features in X_lin\n",
    "n_features = X_lin_test.shape[1]\n",
    "\n",
    "for name in model_names:\n",
    "    model_path = os.path.join(models_dir, f\"{name}_final_coeffs.pkl\")\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model file not found: {model_path}\")\n",
    "        continue\n",
    "    \n",
    "    # Load the coefficients (assuming ndarray)\n",
    "    with open(model_path, 'rb') as f:\n",
    "        coeffs = pickle.load(f)\n",
    "    \n",
    "    if not isinstance(coeffs, np.ndarray):\n",
    "        print(f\"Loaded object for {name} is not a numpy array.\")\n",
    "        continue\n",
    "    \n",
    "    if coeffs.ndim > 1:\n",
    "        coeffs = coeffs.flatten()\n",
    "    \n",
    "    num_coeffs = len(coeffs)\n",
    "    \n",
    "    # Predict on test set and reconstruct full predictions\n",
    "    try:\n",
    "        if name == 'poly':\n",
    "            # Special handling for full polynomial model: degree=2 on all features, with scaling\n",
    "            scaler = StandardScaler().fit(X_lin_train)\n",
    "            poly = PolynomialFeatures(degree=2).fit(X_lin_train)  # include_bias=True by default\n",
    "            \n",
    "            scaled_test = scaler.transform(X_lin_test)\n",
    "            poly_test = poly.transform(scaled_test)\n",
    "            \n",
    "            if num_coeffs != poly_test.shape[1] + 1:\n",
    "                raise ValueError(f\"Coefficients length {num_coeffs} does not match expected for full polynomial: {poly_test.shape[1] + 1}\")\n",
    "            \n",
    "            intercept = coeffs[0]\n",
    "            poly_coef = coeffs[1:]\n",
    "            y_test_pred_adj = intercept + np.dot(poly_test, poly_coef)\n",
    "        else:\n",
    "            # Linear models, assuming no scaling\n",
    "            if num_coeffs == n_features + 1:\n",
    "                X_aug_test = np.column_stack((np.ones(X_lin_test.shape[0]), X_lin_test))\n",
    "                y_test_pred_adj = np.dot(X_aug_test, coeffs)\n",
    "            elif num_coeffs == n_features:\n",
    "                y_test_pred_adj = np.dot(X_lin_test, coeffs)\n",
    "            else:\n",
    "                raise ValueError(f\"For linear model {name}, coefficients length {num_coeffs} does not match n_features={n_features} or n_features+1\")\n",
    "        \n",
    "        y_test_pred = y_test_pred_adj + offset_test\n",
    "        \n",
    "        rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "        r2_test = r2_score(y_test, y_test_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': name.capitalize(),\n",
    "            'RMSE': rmse_test,\n",
    "            'R2': r2_test\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {name}: {str(e)}\")\n",
    "\n",
    "# Create DataFrame and sort by RMSE ascending (best to highest)\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values('RMSE', ascending=True)\n",
    "\n",
    "# Display the table with 5 decimal places\n",
    "print(\"\\nRegression Models Evaluation on Test Set (sorted by RMSE):\\n\")\n",
    "print(df_results.to_string(index=False, float_format=lambda x: '{:.5f}'.format(x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
