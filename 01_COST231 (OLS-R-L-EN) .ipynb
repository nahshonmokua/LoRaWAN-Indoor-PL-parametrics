{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d686399c-11c4-411a-84f5-af4139f3c231",
   "metadata": {},
   "source": [
    "#  COST 231 MWM (OLS / Ridge / Lasso / ElasticNet) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a279780-197b-4624-abfb-b4e7221f9959",
   "metadata": {},
   "source": [
    "#### Imports — core utils, data wrangling, ML, and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22116d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Core + utils\n",
    "from math import sqrt\n",
    "import re\n",
    "import os\n",
    "\n",
    "# ML (scikit-learn)\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Parallel\n",
    "from joblib import Parallel, delayed, dump\n",
    "\n",
    "# Preventing BLAS oversubscription\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_MAX_THREADS\"] = \"1\"\n",
    "\n",
    "# Parallelism settings\n",
    "N_JOBS = -1  # Use all available cores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4becfc4-2aa1-4a60-b330-b71e16141d3a",
   "metadata": {},
   "source": [
    "#### Data paths, loading, and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5957f4cc-7f9a-48ce-993e-2f8151d96d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (aligned with earlier prep)\n",
    "SAVE_DIR   = 'Data+Files+Plots+etc'\n",
    "TRAIN_CSV  = f'{SAVE_DIR}/train.csv'\n",
    "TEST_CSV   = f'{SAVE_DIR}/test.csv'\n",
    "FOLDS_NPY  = f'{SAVE_DIR}/train_folds.npy'\n",
    "\n",
    "# Load splits\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_test  = pd.read_csv(TEST_CSV)\n",
    "fold_assignments = np.load(FOLDS_NPY)\n",
    "\n",
    "# Feature/target setup (COST231-MWM baseline)\n",
    "raw_feats  = ['distance','frequency','c_walls','w_walls']\n",
    "target_col = 'PL'\n",
    "\n",
    "# Train/test matrices\n",
    "Xtr_raw = df_train[raw_feats].copy()\n",
    "ytr_pl  = df_train[target_col].astype(float).values\n",
    "Xte_raw = df_test[raw_feats].copy()\n",
    "yte_pl  = df_test[target_col].astype(float).values\n",
    "\n",
    "def slug(obj):\n",
    "    \"\"\"Filename-safe tag for model/config (kept readable).\"\"\"\n",
    "    if isinstance(obj, dict) and obj:\n",
    "        items = []\n",
    "        for k in sorted(obj.keys()):\n",
    "            v = obj[k]\n",
    "            if isinstance(v, (float, np.floating)): v = float(v)\n",
    "            items.append(f\"{k}={v}\")\n",
    "        s = \"__\".join(items)\n",
    "    else:\n",
    "        s = str(obj) if obj not in (None, {}, []) else \"\"\n",
    "    return re.sub(r\"[^A-Za-z0-9._=-]+\", \"_\", s).strip(\"_\")\n",
    "\n",
    "# Required columns check \n",
    "required_cols = ['PL', 'device_id', 'distance','frequency','c_walls','w_walls']\n",
    "missing = [c for c in required_cols if c not in df_train.columns or c not in df_test.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns in train/test: {missing}\")\n",
    "\n",
    "if len(fold_assignments) != len(df_train):\n",
    "    raise ValueError(f\"fold_assignments length {len(fold_assignments)} != df_train rows {len(df_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acc8f3a-d0d8-4c69-9504-406bc8a025bf",
   "metadata": {},
   "source": [
    "#### Physics-consistent linearization + helpers + model specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b53ff1a5-ad50-4483-af9a-254579ecca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linearize (Friis-adjusted): y_adj = PL - 20*log10(f)\n",
    "d0 = 1.0\n",
    "def z_of_d(d): \n",
    "    return 10.0*np.log10(np.clip(d.astype(float), 1e-6, None)/d0)\n",
    "\n",
    "def f_term(f):\n",
    "    return 20.0*np.log10(np.clip(f.astype(float), 1e-12, None))\n",
    "\n",
    "# Adjusted targets\n",
    "ftr_tr, ftr_te = f_term(Xtr_raw['frequency'].values), f_term(Xte_raw['frequency'].values)\n",
    "ytr_adj, yte_adj = ytr_pl - ftr_tr, yte_pl - ftr_te\n",
    "\n",
    "# Linear feature maps (COST231-MWM baseline: distance + wall counts)\n",
    "cols = ['z_d','c_walls','w_walls']\n",
    "Xtr_lin = pd.DataFrame({\n",
    "    'z_d': z_of_d(Xtr_raw['distance'].values),\n",
    "    'c_walls': Xtr_raw['c_walls'].values,\n",
    "    'w_walls': Xtr_raw['w_walls'].values\n",
    "}, columns=cols).values.astype(float)\n",
    "\n",
    "Xte_lin = pd.DataFrame({\n",
    "    'z_d': z_of_d(Xte_raw['distance'].values),\n",
    "    'c_walls': Xte_raw['c_walls'].values,\n",
    "    'w_walls': Xte_raw['w_walls'].values\n",
    "}, columns=cols).values.astype(float)\n",
    "\n",
    "# Param labels (for reporting)\n",
    "param_names = [\n",
    "    'PL(d0) [dB]', 'Path loss exponent (n)',\n",
    "    'Brick Wall Loss (L_c) [dB]', 'Wood Wall Loss (L_w) [dB]'\n",
    "]\n",
    "\n",
    "# Helpers\n",
    "def unscale_coefficients(pipeline):\n",
    "    \"\"\"Undo StandardScaler effect → coeffs in original units.\"\"\"\n",
    "    steps = pipeline.named_steps\n",
    "    est = steps.get('ridge') or steps.get('lasso') or steps.get('elasticnet') or steps.get('linearregression')\n",
    "    if 'standardscaler' not in steps:\n",
    "        return float(est.intercept_), est.coef_.astype(float).copy()\n",
    "    scaler = steps['standardscaler']\n",
    "    beta_scaled = est.coef_.astype(float)\n",
    "    mu, sig = scaler.mean_, scaler.scale_\n",
    "    beta_orig = beta_scaled / sig\n",
    "    intercept_orig = float(est.intercept_ - np.sum(beta_scaled * mu / sig))\n",
    "    return intercept_orig, beta_orig\n",
    "\n",
    "def fold_indices(folds, k):\n",
    "    val_idx = np.where(folds == k)[0]\n",
    "    tr_idx  = np.where(folds != k)[0]\n",
    "    return tr_idx, val_idx\n",
    "\n",
    "def rmse_r2_on_PL(y_true_pl, y_pred_adj, fterm):\n",
    "    \"\"\"Score in PL-domain (add back freq term).\"\"\"\n",
    "    y_pred_pl = y_pred_adj + fterm\n",
    "    rmse = sqrt(mean_squared_error(y_true_pl, y_pred_pl))\n",
    "    r2   = r2_score(y_true_pl, y_pred_pl)\n",
    "    return rmse, r2\n",
    "\n",
    "# Fold list (ignore negative folds if present)\n",
    "unique_folds = sorted([int(k) for k in np.unique(fold_assignments) if int(k) >= 0])\n",
    "folds = [fold_indices(fold_assignments, k) for k in unique_folds]\n",
    "\n",
    "# Model factories\n",
    "def make_OLS(_): return make_pipeline(LinearRegression())\n",
    "def make_Ridge(cfg): return make_pipeline(StandardScaler(), Ridge(alpha=cfg[\"alpha\"], random_state=42))\n",
    "def make_Lasso(cfg): return make_pipeline(StandardScaler(), Lasso(alpha=cfg[\"alpha\"], max_iter=20000, random_state=42))\n",
    "def make_ElasticNet(cfg): return make_pipeline(\n",
    "    StandardScaler(),\n",
    "    ElasticNet(alpha=cfg[\"alpha\"], l1_ratio=cfg[\"l1_ratio\"], max_iter=20000, random_state=42)\n",
    ")\n",
    "\n",
    "# Grids\n",
    "ridge_grid = [dict(alpha=a) for a in np.logspace(-4, 3, 15)]\n",
    "lasso_grid = [dict(alpha=a) for a in np.logspace(-4, 1, 15)]\n",
    "enet_grid  = [dict(alpha=a, l1_ratio=r) for a in np.logspace(-4, 1, 10) for r in (0.2, 0.5, 0.8)]\n",
    "\n",
    "# Spec list\n",
    "specs = [\n",
    "    (\"OLS\",        make_OLS,        [dict()]),\n",
    "    (\"Ridge\",      make_Ridge,      ridge_grid),\n",
    "    (\"Lasso\",      make_Lasso,      lasso_grid),\n",
    "    (\"ElasticNet\", make_ElasticNet, enet_grid),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ee3cdd-064b-4603-9bbd-a79214ba0760",
   "metadata": {},
   "source": [
    "#### Time-aware K-fold CV on the train split to pick the best config per model variant, then refit on full train subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bac4515-a3ac-44eb-b5ba-badcd9209824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>is_best</th>\n",
       "      <th>cv_rmse_val_mean</th>\n",
       "      <th>cv_rmse_val_sd</th>\n",
       "      <th>cv_r2_val_mean</th>\n",
       "      <th>alpha</th>\n",
       "      <th>l1_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MWM_ElasticNet</td>\n",
       "      <td>True</td>\n",
       "      <td>10.965104</td>\n",
       "      <td>1.143518</td>\n",
       "      <td>0.654180</td>\n",
       "      <td>0.059948</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MWM_Ridge</td>\n",
       "      <td>False</td>\n",
       "      <td>10.973480</td>\n",
       "      <td>1.175072</td>\n",
       "      <td>0.653303</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MWM_Lasso</td>\n",
       "      <td>False</td>\n",
       "      <td>10.973923</td>\n",
       "      <td>1.175701</td>\n",
       "      <td>0.653266</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MWM_OLS</td>\n",
       "      <td>False</td>\n",
       "      <td>10.973923</td>\n",
       "      <td>1.175962</td>\n",
       "      <td>0.653265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  is_best  cv_rmse_val_mean  cv_rmse_val_sd  cv_r2_val_mean  \\\n",
       "0  MWM_ElasticNet     True         10.965104        1.143518        0.654180   \n",
       "1       MWM_Ridge    False         10.973480        1.175072        0.653303   \n",
       "2       MWM_Lasso    False         10.973923        1.175701        0.653266   \n",
       "3         MWM_OLS    False         10.973923        1.175962        0.653265   \n",
       "\n",
       "         alpha  l1_ratio  \n",
       "0     0.059948       0.5  \n",
       "1  1000.000000       NaN  \n",
       "2     0.002683       NaN  \n",
       "3          NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def eval_cfg(factory, cfg):\n",
    "    rmses, r2s = [], []\n",
    "    for tr_idx, val_idx in folds:\n",
    "        pipe = factory(cfg)\n",
    "        pipe.fit(Xtr_lin[tr_idx], ytr_adj[tr_idx])\n",
    "        pred_adj = pipe.predict(Xtr_lin[val_idx])\n",
    "        rmse, r2 = rmse_r2_on_PL(ytr_pl[val_idx], pred_adj, ftr_tr[val_idx])\n",
    "        rmses.append(rmse); r2s.append(r2)\n",
    "    return {\n",
    "        \"cfg\": cfg,\n",
    "        \"rmse_val_mean\": float(np.mean(rmses)) if rmses else np.nan,\n",
    "        \"rmse_val_sd\":   float(np.std(rmses, ddof=1)) if len(rmses) > 1 else 0.0,\n",
    "        \"r2_val_mean\":   float(np.mean(r2s)) if r2s else np.nan,\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, factory, grid in specs:\n",
    "    # Evaluate all configs (parallel over configs)\n",
    "    evals = Parallel(n_jobs=N_JOBS, prefer=\"processes\")(\n",
    "        delayed(eval_cfg)(factory, cfg) for cfg in grid\n",
    "    )\n",
    "\n",
    "    # Pick best config (mean RMSE, then sd, then higher R2)\n",
    "    evals_sorted = sorted(evals, key=lambda e: (e[\"rmse_val_mean\"], e[\"rmse_val_sd\"], -e[\"r2_val_mean\"]))\n",
    "    best = evals_sorted[0]\n",
    "    best_cfg = best[\"cfg\"]\n",
    "\n",
    "    # Fit final on full TRAIN\n",
    "    final_pipe = factory(best_cfg)\n",
    "    final_pipe.fit(Xtr_lin, ytr_adj)\n",
    "\n",
    "    # Test score\n",
    "    yte_pred_adj = final_pipe.predict(Xte_lin)\n",
    "    rmse_te, r2_te = rmse_r2_on_PL(yte_pl, yte_pred_adj, ftr_te)\n",
    "\n",
    "    # Coeffs (original units, adjusted-domain model)\n",
    "    b0, b = unscale_coefficients(final_pipe)\n",
    "    coef_vec = np.concatenate([[b0], b]).astype(float)\n",
    "    coeffs = pd.Series(coef_vec, index=param_names)\n",
    "\n",
    "    model_tag = name if not best_cfg else f\"{name}__{slug(best_cfg)}\"\n",
    "\n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"model_tag\": model_tag,\n",
    "        \"best_cfg\": best_cfg,\n",
    "        \"cv\": {\n",
    "            \"rmse_val_mean\": best[\"rmse_val_mean\"],\n",
    "            \"rmse_val_sd\":   best[\"rmse_val_sd\"],\n",
    "            \"r2_val_mean\":   best[\"r2_val_mean\"],\n",
    "        },\n",
    "        \"test\": {\"rmse\": float(rmse_te), \"r2\": float(r2_te)},\n",
    "        \"final_pipe\": final_pipe,\n",
    "        \"coeffs\": coeffs\n",
    "    })\n",
    "\n",
    "def mwm_short_tag(name: str) -> str:\n",
    "    return f\"MWM_{name}\"\n",
    "\n",
    "# CV-only summary table (TRAIN split only)\n",
    "rows = []\n",
    "for r in results:\n",
    "    cfg = r.get(\"best_cfg\", {}) if isinstance(r.get(\"best_cfg\", {}), dict) else {\"cfg\": str(r.get(\"best_cfg\"))}\n",
    "    rows.append({\n",
    "        \"model\":            mwm_short_tag(r[\"model\"]),\n",
    "        \"is_best\":          False,  # set below after selecting best_overall\n",
    "        \"cv_rmse_val_mean\": r[\"cv\"][\"rmse_val_mean\"],\n",
    "        \"cv_rmse_val_sd\":   r[\"cv\"][\"rmse_val_sd\"],\n",
    "        \"cv_r2_val_mean\":   r[\"cv\"][\"r2_val_mean\"],\n",
    "        \"alpha\":            cfg.get(\"alpha\", np.nan),\n",
    "        \"l1_ratio\":         cfg.get(\"l1_ratio\", np.nan),\n",
    "    })\n",
    "\n",
    "mwm_cv_table = (pd.DataFrame(rows)\n",
    "                .sort_values([\"cv_rmse_val_mean\", \"cv_rmse_val_sd\", \"model\"])\n",
    "                .reset_index(drop=True))\n",
    "\n",
    "# Mark best overall (same logic you use later)\n",
    "best_overall = min(results, key=lambda r: (r[\"cv\"][\"rmse_val_mean\"], r[\"cv\"][\"rmse_val_sd\"], -r[\"cv\"][\"r2_val_mean\"]))\n",
    "best_long_tag = best_overall[\"model_tag\"]\n",
    "mwm_cv_table[\"is_best\"] = mwm_cv_table[\"model\"].eq(mwm_short_tag(best_overall[\"model\"]))\n",
    "\n",
    "display(mwm_cv_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab23568",
   "metadata": {},
   "source": [
    "#### Fitting CV summary (mean ± sd across folds), best model highlighted, then OOF residuals for BEST are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7151be09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] Saved best COST231_MWM test residuals: Data+Files+Plots+etc/residuals__COST231_MWM__BEST__test.csv\n",
      "\n",
      "[OOF] Saved best COST231_MWM OOF residuals: Data+Files+Plots+etc/residuals__COST231_MWM__BEST__oof.csv\n"
     ]
    }
   ],
   "source": [
    "best_name     = best_overall[\"model\"]      # OLS / Ridge / Lasso / ElasticNet\n",
    "best_cfg      = best_overall[\"best_cfg\"]\n",
    "best_long_tag = best_overall[\"model_tag\"]\n",
    "\n",
    "best_tag_short = mwm_short_tag(best_name)\n",
    "\n",
    "# BEST residuals on TEST (refit on full TRAIN already stored in best_overall[\"final_pipe\"])\n",
    "best_pipe = best_overall[\"final_pipe\"]\n",
    "yte_pred_adj = best_pipe.predict(Xte_lin)\n",
    "\n",
    "PL_pred_test = yte_pred_adj + ftr_te\n",
    "resid_test   = yte_pl - PL_pred_test\n",
    "\n",
    "mwm_test_df = pd.DataFrame({\n",
    "    \"model\":       \"COST231_MWM_BEST\",\n",
    "    \"variant\":     best_tag_short,\n",
    "    \"split\":       \"test\",\n",
    "    \"row_id\":      np.arange(len(df_test), dtype=int),\n",
    "    \"time\":        df_test.get(\"time\", pd.Series(index=df_test.index, dtype=float)).values,\n",
    "    \"device_id\":   df_test[\"device_id\"].values,\n",
    "    \"distance\":    df_test[\"distance\"].values,\n",
    "    \"frequency\":   df_test[\"frequency\"].values,\n",
    "    \"c_walls\":     df_test[\"c_walls\"].values,\n",
    "    \"w_walls\":     df_test[\"w_walls\"].values,\n",
    "    \"PL_true\":     yte_pl,\n",
    "    \"PL_pred\":     PL_pred_test,\n",
    "    \"resid_db\":    resid_test\n",
    "})\n",
    "\n",
    "test_path = f\"{SAVE_DIR}/residuals__COST231__BEST__test.csv\"\n",
    "mwm_test_df.to_csv(test_path, index=False)\n",
    "print(f\"\\n[TEST] Saved best COST231_MWM test residuals: {test_path}\")\n",
    "\n",
    "# OOF residuals for BEST (train-only)\n",
    "factory_for_best = next(f for (n, f, g) in specs if n == best_name)\n",
    "\n",
    "y_pred_adj_oof = np.full(len(ytr_adj), np.nan, dtype=float)\n",
    "for tr_idx, val_idx in folds:\n",
    "    pipe = factory_for_best(best_cfg)\n",
    "    pipe.fit(Xtr_lin[tr_idx], ytr_adj[tr_idx])\n",
    "    y_pred_adj_oof[val_idx] = pipe.predict(Xtr_lin[val_idx])\n",
    "\n",
    "mask = ~np.isnan(y_pred_adj_oof)\n",
    "\n",
    "PL_pred_oof = y_pred_adj_oof[mask] + ftr_tr[mask]\n",
    "resid_oof   = ytr_pl[mask] - PL_pred_oof\n",
    "\n",
    "mwm_oof_df = pd.DataFrame({\n",
    "    \"model\":       \"COST231_MWM_BEST\",\n",
    "    \"variant\":     best_tag_short,\n",
    "    \"split\":       \"oof\",\n",
    "    \"row_id\":      np.arange(len(df_train), dtype=int)[mask],\n",
    "    \"fold\":        fold_assignments.astype(int)[mask],\n",
    "    \"time\":        df_train.get(\"time\", pd.Series(index=df_train.index, dtype=float)).values[mask],\n",
    "    \"device_id\":   df_train[\"device_id\"].values[mask],\n",
    "    \"distance\":    df_train[\"distance\"].values[mask],\n",
    "    \"frequency\":   df_train[\"frequency\"].values[mask],\n",
    "    \"c_walls\":     df_train[\"c_walls\"].values[mask],\n",
    "    \"w_walls\":     df_train[\"w_walls\"].values[mask],\n",
    "    \"PL_true\":     ytr_pl[mask],\n",
    "    \"PL_pred\":     PL_pred_oof,\n",
    "    \"resid_db\":    resid_oof\n",
    "})\n",
    "\n",
    "oof_path = f\"{SAVE_DIR}/residuals__COST231__BEST__oof.csv\"\n",
    "mwm_oof_df.to_csv(oof_path, index=False)\n",
    "print(f\"\\n[OOF] Saved best COST231 OOF residuals: {oof_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ade18d-2b5b-49f0-ab79-1e307b4a2c48",
   "metadata": {},
   "source": [
    "#### Final held-out evaluation on the 20% test split for the CV-selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "227ff3e9-2ac2-428e-a348-bae813972184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OLS</td>\n",
       "      <td>12.070405</td>\n",
       "      <td>0.589023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>12.070322</td>\n",
       "      <td>0.589029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>12.069744</td>\n",
       "      <td>0.589068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>12.061215</td>\n",
       "      <td>0.589648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model  Test RMSE   Test R2\n",
       "0         OLS  12.070405  0.589023\n",
       "1       Ridge  12.070322  0.589029\n",
       "2       Lasso  12.069744  0.589068\n",
       "3  ElasticNet  12.061215  0.589648"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Final test evaluation (held-out 20%): selected model only\n",
    "test_rows = []\n",
    "for res in results:\n",
    "    te = res[\"test\"]\n",
    "    test_rows.append({\n",
    "        \"Model\": res[\"model\"],\n",
    "        \"Test RMSE\": float(te[\"rmse\"]),\n",
    "        \"Test R2\":   float(te[\"r2\"]),\n",
    "    })\n",
    "\n",
    "# Frame + display\n",
    "test_df = pd.DataFrame(test_rows)\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e08ee0b-940e-4f89-9896-5f61b8795b9f",
   "metadata": {},
   "source": [
    "#### Coefficient table (all models, final fits, original units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f8730ff-5c50-4f0d-ad3a-ebcf9f1da4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Harmonized Coefficients (final all-train fits, original units) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OLS</th>\n",
       "      <th>Ridge</th>\n",
       "      <th>Lasso</th>\n",
       "      <th>ElasticNet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PL(d0) [dB]</th>\n",
       "      <td>-32.747465</td>\n",
       "      <td>-32.669933</td>\n",
       "      <td>-32.759432</td>\n",
       "      <td>-29.604407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Path loss exponent (n)</th>\n",
       "      <td>4.227210</td>\n",
       "      <td>4.219631</td>\n",
       "      <td>4.229175</td>\n",
       "      <td>3.935890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brick Wall Loss (L_c) [dB]</th>\n",
       "      <td>7.800822</td>\n",
       "      <td>7.805277</td>\n",
       "      <td>7.793905</td>\n",
       "      <td>7.858416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wood Wall Loss (L_w) [dB]</th>\n",
       "      <td>1.694792</td>\n",
       "      <td>1.703944</td>\n",
       "      <td>1.690098</td>\n",
       "      <td>1.999144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  OLS      Ridge      Lasso  ElasticNet\n",
       "PL(d0) [dB]                -32.747465 -32.669933 -32.759432  -29.604407\n",
       "Path loss exponent (n)       4.227210   4.219631   4.229175    3.935890\n",
       "Brick Wall Loss (L_c) [dB]   7.800822   7.805277   7.793905    7.858416\n",
       "Wood Wall Loss (L_w) [dB]    1.694792   1.703944   1.690098    1.999144"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Collect coeffs side by side\n",
    "coef_df = pd.concat([res['coeffs'] for res in results], axis=1)\n",
    "coef_df.columns = [res['model'] for res in results]\n",
    "\n",
    "print(\"\\n Harmonized Coefficients (final all-train fits, original units) \")\n",
    "display(coef_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general101 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
