{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6875a4b9-49de-436a-8f12-51bd64887285",
   "metadata": {},
   "source": [
    "# BLR (Conjugate / g-prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2cb487-a8a2-43aa-80c9-720558fd3666",
   "metadata": {},
   "source": [
    "#### Speed specifications & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59aa85a3-740f-4817-b06f-3fa05bea52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "from joblib import Parallel, delayed, dump\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "from math import sqrt\n",
    "\n",
    "#  SPEED HEADER (single-BLAS + joblib CV) \n",
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_MAX_THREADS\"] = \"1\"\n",
    "\n",
    "# Parallelism knob \n",
    "N_JOBS = -1 # Use all available cores\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Print fold-by-fold metrics?\n",
    "VERBOSE_CV = False  #  False to parallelize configs with clean logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313fa3f6-0f20-4aec-a4f7-f5ae80b7502d",
   "metadata": {},
   "source": [
    "#### Paths, Data Loading & Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f11c2c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR   = 'Data+Files+Plots+etc'\n",
    "TRAIN_CSV  = f'{SAVE_DIR}/train.csv'\n",
    "TEST_CSV   = f'{SAVE_DIR}/test.csv'\n",
    "FOLDS_NPY  = f'{SAVE_DIR}/train_folds.npy' \n",
    "\n",
    "# Output paths for residuals\n",
    "RESID_DIR_OOF = \"Data+Files+Plots+etc/Reports\"  # OOF Residuals\n",
    "os.makedirs(RESID_DIR_OOF, exist_ok=True)\n",
    "\n",
    "def slug(obj):\n",
    "    \"\"\"Filename-safe tag for params.\"\"\"\n",
    "    if isinstance(obj, dict) and obj:\n",
    "        parts = []\n",
    "        for k in sorted(obj.keys()):\n",
    "            v = obj[k]\n",
    "            if isinstance(v, (float, np.floating)): v = float(v)\n",
    "            parts.append(f\"{k}={v}\")\n",
    "        s = \"__\".join(parts)\n",
    "    else:\n",
    "        s = str(obj) if obj not in (None, {}, []) else \"\"\n",
    "    return re.sub(r\"[^A-Za-z0-9._=-]+\", \"_\", s).strip(\"_\")\n",
    "\n",
    "#  Load splits \n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_train[\"_rowpos\"] = np.arange(len(df_train), dtype=int)\n",
    "df_test  = pd.read_csv(TEST_CSV)\n",
    "\n",
    "#  Required columns check \n",
    "required_cols = [\n",
    "    'PL','distance','frequency','c_walls','w_walls',\n",
    "    'co2','humidity','pm25','pressure','temperature','snr'\n",
    "]\n",
    "missing = [c for c in required_cols if c not in df_train.columns or c not in df_test.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns in train/test: {missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e22992-05e9-4d45-9526-1c8dda89639d",
   "metadata": {},
   "source": [
    "#### Cross-Validation Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbd17e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] Using saved folds (remapped) | K=5 | n_train=1663627 | fold sizes=[554543, 277271, 277271, 277271, 277271]\n"
     ]
    }
   ],
   "source": [
    "fold_assignments_full = np.load(FOLDS_NPY)  # vector aligned \n",
    "\n",
    "rowpos = df_train[\"_rowpos\"].to_numpy(dtype=int)\n",
    "if rowpos.max() >= len(fold_assignments_full):\n",
    "    raise ValueError(\n",
    "        f\"[folds] Mismatch: train_folds.npy len={len(fold_assignments_full)} < max(_rowpos)={rowpos.max()}.\\n\"\n",
    "        f\"train.csv and train_folds.npy are out of sync.\"\n",
    "    )\n",
    "fold_assignments = fold_assignments_full[rowpos]\n",
    "\n",
    "K = int(fold_assignments.max()) + 1\n",
    "folds = [(np.where(fold_assignments != k)[0], np.where(fold_assignments == k)[0]) for k in range(K)]\n",
    "print(f\"[CV] Using saved folds (remapped) | K={K} | n_train={len(df_train)} | \"\n",
    "      f\"fold sizes={[len(v) for _, v in folds]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477056ca-f881-45b9-bbb6-051e0708dbf2",
   "metadata": {},
   "source": [
    "#### Physics, Features & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47627831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physics helpers \n",
    "d0 = 1.0  # reference distance in meters\n",
    "\n",
    "def z_of_d(d):\n",
    "    d = np.clip(d.astype(float), 1e-6, None)\n",
    "    return 10.0 * np.log10(d / d0)\n",
    "\n",
    "def f_term(f):\n",
    "    f = np.clip(f.astype(float), 1e-12, None)\n",
    "    return 20.0 * np.log10(f)\n",
    "\n",
    "#  Features & targets \n",
    "raw_feats  = ['distance','frequency','c_walls','w_walls',\n",
    "              'co2','humidity','pm25','pressure','temperature','snr']\n",
    "target_col = 'PL'\n",
    "\n",
    "Xtr_raw = df_train[raw_feats].copy()\n",
    "ytr_pl  = df_train[target_col].astype(float).values\n",
    "Xte_raw = df_test[raw_feats].copy()\n",
    "yte_pl  = df_test[target_col].astype(float).values\n",
    "\n",
    "# Friis adjustment: y_adj = PL - 20*log10(f)\n",
    "ftr_tr, ftr_te = f_term(Xtr_raw['frequency'].values), f_term(Xte_raw['frequency'].values)\n",
    "ytr_adj, yte_adj = ytr_pl - ftr_tr, yte_pl - ftr_te\n",
    "\n",
    "# Linear feature map used by BLR\n",
    "LIN_COLS = ['z_d','c_walls','w_walls','co2','humidity','pm25','pressure','temperature','snr']\n",
    "\n",
    "Xtr_lin = pd.DataFrame({\n",
    "    'z_d': z_of_d(Xtr_raw['distance'].values),\n",
    "    'c_walls': Xtr_raw['c_walls'].values,\n",
    "    'w_walls': Xtr_raw['w_walls'].values,\n",
    "    'co2': Xtr_raw['co2'].values,\n",
    "    'humidity': Xtr_raw['humidity'].values,\n",
    "    'pm25': Xtr_raw['pm25'].values,\n",
    "    'pressure': Xtr_raw['pressure'].values,\n",
    "    'temperature': Xtr_raw['temperature'].values,\n",
    "    'snr': Xtr_raw['snr'].values\n",
    "}, columns=LIN_COLS).values\n",
    "\n",
    "Xte_lin = pd.DataFrame({\n",
    "    'z_d': z_of_d(Xte_raw['distance'].values),\n",
    "    'c_walls': Xte_raw['c_walls'].values,\n",
    "    'w_walls': Xte_raw['w_walls'].values,\n",
    "    'co2': Xte_raw['co2'].values,\n",
    "    'humidity': Xte_raw['humidity'].values,\n",
    "    'pm25': Xte_raw['pm25'].values,\n",
    "    'pressure': Xte_raw['pressure'].values,\n",
    "    'temperature': Xte_raw['temperature'].values,\n",
    "    'snr': Xte_raw['snr'].values\n",
    "}, columns=LIN_COLS).values\n",
    "\n",
    "# Metrics (PL-domain) \n",
    "def rmse_r2_on_PL(y_true_pl, y_pred_adj, fterm):\n",
    "    y_pred_pl = y_pred_adj + fterm\n",
    "    rmse = sqrt(((y_true_pl - y_pred_pl) ** 2).mean())\n",
    "    ss_res = ((y_true_pl - y_pred_pl) ** 2).sum()\n",
    "    ss_tot = ((y_true_pl - y_true_pl.mean()) ** 2).sum()\n",
    "    r2 = 1.0 - ss_res / ss_tot if ss_tot > 0 else np.nan\n",
    "    return rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4491b65-9b1c-48a9-946b-a9a0cf039ecf",
   "metadata": {},
   "source": [
    "#### BLR Estimators (Conjugate & g-prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aaa06fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLR estimators (Conjugate) \n",
    "class FullBLRConjugate(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Conjugate Bayesian Linear Regression with Normal–Inverse-Gamma prior:\n",
    "        beta | sigma^2 ~ N(beta0, sigma^2 V0),  sigma^2 ~ Inv-Gamma(a0, b0)\n",
    "    - Works on adjusted target (y = PL - 20 log10 f).\n",
    "    - Adds intercept internally (augments X with a column of ones).\n",
    "    - Assumes you standardized X upstream if using spherical V0 (we do via StandardScaler).\n",
    "    \"\"\"\n",
    "    def __init__(self, beta0=None, V0_scale=1e6, a0=1e-2, b0=1e-2):\n",
    "        self.beta0 = beta0\n",
    "        self.V0_scale = float(V0_scale)\n",
    "        self.a0 = float(a0)\n",
    "        self.b0 = float(b0)\n",
    "        # learned\n",
    "        self.beta_n_ = None\n",
    "        self.Vn_ = None\n",
    "        self.an_ = None\n",
    "        self.bn_ = None\n",
    "\n",
    "    def _augment(self, X):\n",
    "        n = X.shape[0]\n",
    "        return np.hstack([np.ones((n, 1)), X])\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float).reshape(-1)\n",
    "        X_aug = self._augment(X)         # [n x (p+1)]\n",
    "        n, d = X_aug.shape\n",
    "\n",
    "        beta0 = np.zeros(d) if self.beta0 is None else np.asarray(self.beta0, dtype=float).reshape(-1)\n",
    "        if beta0.shape[0] != d:\n",
    "            raise ValueError(\"beta0 size mismatch.\")\n",
    "\n",
    "        # Prior covariance: V0 = V0_scale * I_d  (weakly informative on standardized X)\n",
    "        V0_inv = np.eye(d) / self.V0_scale\n",
    "\n",
    "        XtX = X_aug.T @ X_aug\n",
    "        Vn_inv = V0_inv + XtX\n",
    "        # small jitter for numerical stability\n",
    "        Vn = np.linalg.inv(Vn_inv + 1e-12*np.eye(d))\n",
    "\n",
    "        Xty = X_aug.T @ y\n",
    "        beta_n = Vn @ (V0_inv @ beta0 + Xty)\n",
    "\n",
    "        an = self.a0 + 0.5 * n\n",
    "        # bn two equivalent forms; this one is numerically stable:\n",
    "        bn = self.b0 + 0.5*( y @ y + beta0 @ (V0_inv @ beta0) - beta_n @ (Vn_inv @ beta_n) )\n",
    "\n",
    "        self.beta_n_ = beta_n\n",
    "        self.Vn_ = Vn\n",
    "        self.an_ = an\n",
    "        self.bn_ = float(bn)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, return_std=False):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        X_aug = self._augment(X)\n",
    "        mean = X_aug @ self.beta_n_\n",
    "        if not return_std:\n",
    "            return mean\n",
    "        # predictive variance for y: (bn/an) * (1 + x^T Vn x)\n",
    "        pred_var = (self.bn_ / self.an_) * (1.0 + np.sum((X_aug @ self.Vn_) * X_aug, axis=1))\n",
    "        pred_std = np.sqrt(np.maximum(pred_var, 0.0))\n",
    "        return mean, pred_std\n",
    "\n",
    "# BLR estimators ( g-prior) \n",
    "class BLR_GPrior(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Zellner g-prior on slopes (intercept gets flat/improper prior):\n",
    "      beta = [beta0 (intercept); beta_s] ;  beta_s | sigma^2 ~ N(0, g sigma^2 (X'X)^{-1})\n",
    "    - g_mode: 'uip' (g = n), or 'eb' (empirical Bayes from OLS R^2).\n",
    "    - Works on adjusted target; adds intercept internally; expects standardized X.\n",
    "    \"\"\"\n",
    "    def __init__(self, g_mode='uip', a0=1e-2, b0=1e-2, g_fixed=None):\n",
    "        self.g_mode = str(g_mode)\n",
    "        self.a0 = float(a0)\n",
    "        self.b0 = float(b0)\n",
    "        self.g_fixed = None if g_fixed is None else float(g_fixed)\n",
    "        # learned\n",
    "        self.beta_n_ = None\n",
    "        self.Vn_ = None\n",
    "        self.an_ = None\n",
    "        self.bn_ = None\n",
    "        self.g_ = None\n",
    "\n",
    "    def _augment(self, X):\n",
    "        n = X.shape[0]\n",
    "        return np.hstack([np.ones((n, 1)), X])\n",
    "\n",
    "    def _ols_fit(self, X_aug, y):\n",
    "        # least squares solution\n",
    "        beta_ols, *_ = np.linalg.lstsq(X_aug, y, rcond=None)\n",
    "        yhat = X_aug @ beta_ols\n",
    "        resid = y - yhat\n",
    "        return beta_ols, yhat, resid\n",
    "\n",
    "    def _choose_g(self, X_aug, y):\n",
    "        n, d = X_aug.shape\n",
    "        p = d - 1  # number of slopes\n",
    "        if self.g_fixed is not None:\n",
    "            return max(self.g_fixed, 1e-8)\n",
    "        if self.g_mode.lower() == 'uip':\n",
    "            return float(n)\n",
    "        # empirical Bayes from OLS R^2\n",
    "        beta_ols, yhat, resid = self._ols_fit(X_aug, y)\n",
    "        tss = ((y - y.mean())**2).sum()\n",
    "        rss = (resid**2).sum()\n",
    "        R2 = 0.0 if tss <= 0 else max(0.0, 1.0 - rss / tss)\n",
    "        R2 = min(R2, 1.0 - 1e-8)\n",
    "        # g_hat = max( (R2/(1-R2)) * (n - p - 1), 1e-8 )\n",
    "        g_hat = (R2 / (1.0 - R2)) * max(n - p - 1, 1.0)\n",
    "        return float(np.clip(g_hat, 1e-8, 1e12))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        y = np.asarray(y, dtype=float).reshape(-1)\n",
    "        X_aug = self._augment(X)  # [n x (p+1)]\n",
    "        n, d = X_aug.shape\n",
    "        p = d - 1\n",
    "\n",
    "        g = self._choose_g(X_aug, y)\n",
    "        self.g_ = g\n",
    "\n",
    "        # Build prior precision: V0_inv = diag([0, (1/g)*XtX_slopes]) in augmented coords\n",
    "        # Compute blocks\n",
    "        one = X_aug[:, [0]]           # intercept column (ones)\n",
    "        Z   = X_aug[:, 1:]            # slopes (standardized)\n",
    "        XtX_11 = (one.T @ one)        # scalar [1x1] = n\n",
    "        XtX_12 = (one.T @ Z)          # [1 x p]\n",
    "        XtX_22 = (Z.T @ Z)            # [p x p]\n",
    "\n",
    "        V0_inv = np.zeros((d, d), dtype=float)\n",
    "        if p > 0:\n",
    "            V0_inv[1:, 1:] = (1.0 / g) * XtX_22\n",
    "\n",
    "        XtX = X_aug.T @ X_aug\n",
    "        Vn_inv = V0_inv + XtX\n",
    "        Vn = np.linalg.inv(Vn_inv + 1e-12*np.eye(d))\n",
    "\n",
    "        Xty = X_aug.T @ y\n",
    "        beta_n = Vn @ Xty  # prior mean = 0 (on slopes), flat on intercept\n",
    "\n",
    "        an = self.a0 + 0.5 * n\n",
    "        # bn form with prior precision:\n",
    "        bn = self.b0 + 0.5*( y @ y - beta_n @ (Vn_inv @ beta_n) )\n",
    "\n",
    "        self.beta_n_ = beta_n\n",
    "        self.Vn_ = Vn\n",
    "        self.an_ = an\n",
    "        self.bn_ = float(bn)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, return_std=False):\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        X_aug = self._augment(X)\n",
    "        mean = X_aug @ self.beta_n_\n",
    "        if not return_std:\n",
    "            return mean\n",
    "        pred_var = (self.bn_ / self.an_) * (1.0 + np.sum((X_aug @ self.Vn_) * X_aug, axis=1))\n",
    "        pred_std = np.sqrt(np.maximum(pred_var, 0.0))\n",
    "        return mean, pred_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3aee11-aee5-49e2-82f0-5bcf9138dfee",
   "metadata": {},
   "source": [
    "#### Pipeline Builders & Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a1ebf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline builders \n",
    "def build_blr_conjugate(cfg):\n",
    "    # Standardize X; conjugate BLR on adjusted target\n",
    "    return make_pipeline(\n",
    "        StandardScaler(with_mean=True, with_std=True),\n",
    "        FullBLRConjugate(beta0=None, V0_scale=cfg[\"V0_scale\"], a0=cfg[\"a0\"], b0=cfg[\"b0\"])\n",
    "    )\n",
    "\n",
    "def build_blr_gprior(cfg):\n",
    "    # Standardize X; g-prior BLR on adjusted target\n",
    "    return make_pipeline(\n",
    "        StandardScaler(with_mean=True, with_std=True),\n",
    "        BLR_GPrior(g_mode=cfg[\"g_mode\"], a0=cfg[\"a0\"], b0=cfg[\"b0\"])\n",
    "    )\n",
    "\n",
    "# Grids \n",
    "conj_grid = [dict(V0_scale=v, a0=1e-2, b0=1e-2) for v in (1e2, 1e3, 1e4, 1e5, 1e6)]\n",
    "gprior_grid = [dict(g_mode=m, a0=1e-2, b0=1e-2) for m in (\"uip\",\"eb\")]\n",
    "\n",
    "blr_specs = [\n",
    "    (\"BLR-Linear (Conjugate)\", build_blr_conjugate, conj_grid),\n",
    "    (\"BLR-Linear (g-prior)\",   build_blr_gprior,   gprior_grid),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fed175-0250-4d90-a57d-af10ff30e9f1",
   "metadata": {},
   "source": [
    "#### Posterior Unscaling (Original Units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edc1fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Unscale BLR posterior to original units \n",
    "def unscale_blr_posterior(pipeline, feat_names):\n",
    "    \"\"\"\n",
    "    Map posterior (intercept + standardized coefs) back to original feature units.\n",
    "    Returns (names, mean_orig, cov_orig).\n",
    "    \"\"\"\n",
    "    steps = pipeline.named_steps\n",
    "    scaler = steps['standardscaler']\n",
    "    est = steps['fullblrconjugate'] if 'fullblrconjugate' in steps else steps['blr_gprior']\n",
    "\n",
    "    beta_std = est.beta_n_.copy()         # length p+1\n",
    "    Vn_std   = est.Vn_.copy()             # (p+1)x(p+1)\n",
    "\n",
    "    mu = scaler.mean_.astype(float)\n",
    "    sig = scaler.scale_.astype(float)\n",
    "    p = len(mu)\n",
    "\n",
    "    # Transform matrix T from [intercept, beta_std] -> [intercept_orig, beta_orig]\n",
    "    T = np.zeros((p+1, p+1), dtype=float)\n",
    "    T[0,0] = 1.0\n",
    "    T[0,1:] = -mu / sig\n",
    "    for j in range(p):\n",
    "        T[j+1, j+1] = 1.0 / sig[j]\n",
    "\n",
    "    beta_orig = T @ beta_std\n",
    "    Vn_orig = T @ Vn_std @ T.T\n",
    "\n",
    "    names = [\"Intercept\"] + list(feat_names)\n",
    "    return names, beta_orig, Vn_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9416d5-8fdf-4681-bfd0-75c9e54bccdd",
   "metadata": {},
   "source": [
    "#### CV sweep (folded TRAIN), select best config per BLR variant, refit, and score on TEST (kept in-memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f9504313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CV for 2 BLR variants | K=5 folds | grid eval=parallel...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done processing!\n"
     ]
    }
   ],
   "source": [
    "# K-fold CV over each BLR model\n",
    "blr_results = []\n",
    "blr_residuals_list = []\n",
    "\n",
    "K = int(np.max(fold_assignments)) + 1\n",
    "\n",
    "# (train_idx, val_idx) per fold, derived directly from fold_assignments\n",
    "folds = [(np.flatnonzero(fold_assignments != k),\n",
    "          np.flatnonzero(fold_assignments == k)) for k in range(K)]\n",
    "\n",
    "print(f\"Running CV for {len(blr_specs)} BLR variants | K={len(folds)} folds | grid eval={'parallel...' if (N_JOBS != 1) else 'sequential...'}\")\n",
    "\n",
    "def eval_cfg_blr(factory, cfg, folds):\n",
    "    tr_rmse_list, val_rmse_list, tr_r2_list, val_r2_list = [], [], [], []\n",
    "\n",
    "    for tr_idx, val_idx in folds:\n",
    "        X_tr, X_val = Xtr_lin[tr_idx], Xtr_lin[val_idx]\n",
    "        y_tr, y_val = ytr_adj[tr_idx], ytr_adj[val_idx]\n",
    "        ypl_tr, ypl_val = ytr_pl[tr_idx], ytr_pl[val_idx]\n",
    "        f_tr,  f_val  = ftr_tr[tr_idx],  ftr_tr[val_idx]\n",
    "\n",
    "        pipe = factory(cfg)\n",
    "        with threadpool_limits(limits=1, user_api=\"blas\"):\n",
    "            pipe.fit(X_tr, y_tr)\n",
    "\n",
    "        y_tr_pred = pipe.predict(X_tr)\n",
    "        rmse_tr, r2_tr = rmse_r2_on_PL(ypl_tr, y_tr_pred, f_tr)\n",
    "        tr_rmse_list.append(rmse_tr); tr_r2_list.append(r2_tr)\n",
    "\n",
    "        y_val_pred = pipe.predict(X_val)\n",
    "        rmse_val, r2_val = rmse_r2_on_PL(ypl_val, y_val_pred, f_val)\n",
    "        val_rmse_list.append(rmse_val); val_r2_list.append(r2_val)\n",
    "\n",
    "    return {\n",
    "        \"cfg\": cfg,\n",
    "        \"rmse_train_mean\": float(np.mean(tr_rmse_list)), \"rmse_train_sd\": float(np.std(tr_rmse_list)),\n",
    "        \"rmse_val_mean\":   float(np.mean(val_rmse_list)), \"rmse_val_sd\":   float(np.std(val_rmse_list)),\n",
    "        \"r2_train_mean\":   float(np.mean(tr_r2_list)),    \"r2_train_sd\":    float(np.std(tr_r2_list)),\n",
    "        \"r2_val_mean\":     float(np.mean(val_r2_list)),   \"r2_val_sd\":      float(np.std(val_r2_list)),\n",
    "    }\n",
    "\n",
    "for name, factory, grid in blr_specs:\n",
    "    if len(grid) == 1:\n",
    "        grid_results = [eval_cfg_blr(factory, grid[0], folds)]\n",
    "    else:\n",
    "        grid_results = Parallel(n_jobs=N_JOBS, backend=\"threading\", prefer=\"threads\", verbose=0)(\n",
    "            delayed(eval_cfg_blr)(factory, cfg, folds) for cfg in grid\n",
    "        )\n",
    "\n",
    "    best_res = min(grid_results, key=lambda r: r[\"rmse_val_mean\"])\n",
    "    best_cfg, best_cv = best_res[\"cfg\"], {k: v for k, v in best_res.items() if k != \"cfg\"}\n",
    "\n",
    "    final_pipe = factory(best_cfg)\n",
    "    with threadpool_limits(limits=1, user_api=\"blas\"):\n",
    "        final_pipe.fit(Xtr_lin, ytr_adj)\n",
    "\n",
    "    # Test performance (PL domain)\n",
    "    try:\n",
    "        yte_pred_adj, yte_pred_std = final_pipe.predict(Xte_lin, return_std=True)\n",
    "    except TypeError:\n",
    "        yte_pred_adj = final_pipe.predict(Xte_lin)\n",
    "        yte_pred_std = None\n",
    "\n",
    "    test_rmse, test_r2 = rmse_r2_on_PL(yte_pl, yte_pred_adj, ftr_te)\n",
    "\n",
    "    # Residuals on TEST (in-memory)\n",
    "    PL_pred  = yte_pred_adj + ftr_te\n",
    "    resid_db = yte_pl - PL_pred\n",
    "\n",
    "    model_tag = f\"BLR_{name}\"\n",
    "\n",
    "    # Posterior means & std errors (original units)\n",
    "    names_u, mean_u, cov_u = unscale_blr_posterior(final_pipe, LIN_COLS)\n",
    "    se_u = np.sqrt(np.clip(np.diag(cov_u), 0.0, None))\n",
    "    coef_tbl = pd.DataFrame({\"mean\": mean_u, \"std_err\": se_u}, index=names_u)\n",
    "\n",
    "    blr_results.append({\n",
    "        \"model\":      name,\n",
    "        \"best_cfg\":   best_cfg,\n",
    "        \"cv\":         best_cv,\n",
    "        \"test\":       {\"rmse\": float(test_rmse), \"r2\": float(test_r2)},\n",
    "        \"final_pipe\": final_pipe,\n",
    "        \"coef_tbl\":   coef_tbl,\n",
    "        \"model_tag\":  model_tag\n",
    "    })\n",
    "\n",
    "print(\"\\nDone processing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8835cd42",
   "metadata": {},
   "source": [
    "#### BLR CV summary (mean ± sd across folds), best model highlighted, then OOF residuals for BEST are saved.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39b7bae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>is_best</th>\n",
       "      <th>cv_rmse_val_mean</th>\n",
       "      <th>cv_rmse_val_sd</th>\n",
       "      <th>cv_r2_val_mean</th>\n",
       "      <th>cfg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLR_BLR-Linear (g-prior)</td>\n",
       "      <td>True</td>\n",
       "      <td>8.241577</td>\n",
       "      <td>0.582734</td>\n",
       "      <td>0.805532</td>\n",
       "      <td>a0=0.01__b0=0.01__g_mode=uip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLR_BLR-Linear (Conjugate)</td>\n",
       "      <td>False</td>\n",
       "      <td>8.241577</td>\n",
       "      <td>0.582735</td>\n",
       "      <td>0.805532</td>\n",
       "      <td>V0_scale=100.0__a0=0.01__b0=0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  is_best  cv_rmse_val_mean  cv_rmse_val_sd  \\\n",
       "0    BLR_BLR-Linear (g-prior)     True          8.241577        0.582734   \n",
       "1  BLR_BLR-Linear (Conjugate)    False          8.241577        0.582735   \n",
       "\n",
       "   cv_r2_val_mean                               cfg  \n",
       "0        0.805532      a0=0.01__b0=0.01__g_mode=uip  \n",
       "1        0.805532  V0_scale=100.0__a0=0.01__b0=0.01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST] Saved best BLR test residuals: Data+Files+Plots+etc/Reports/residuals__BLR__BEST__test.csv\n",
      "\n",
      "[OOF] Saved best BLR OOF residuals: Data+Files+Plots+etc/Reports/residuals__BLR__BEST__oof.csv\n"
     ]
    }
   ],
   "source": [
    "best_overall  = min(blr_results, key=lambda r: r[\"cv\"][\"rmse_val_mean\"])\n",
    "best_name     = best_overall[\"model\"]\n",
    "best_cfg      = best_overall[\"best_cfg\"]\n",
    "best_long_tag = best_overall[\"model_tag\"]\n",
    "\n",
    "rows = []\n",
    "for r in blr_results:\n",
    "    cfg = r.get(\"best_cfg\", {}) if isinstance(r.get(\"best_cfg\", {}), dict) else {\"cfg\": str(r.get(\"best_cfg\"))}\n",
    "    rows.append({\n",
    "        \"model\":            f\"BLR_{r['model']}\",\n",
    "        \"is_best\":          (r[\"model_tag\"] == best_long_tag),\n",
    "        \"cv_rmse_val_mean\": r[\"cv\"][\"rmse_val_mean\"],\n",
    "        \"cv_rmse_val_sd\":   r[\"cv\"][\"rmse_val_sd\"],\n",
    "        \"cv_r2_val_mean\":   r[\"cv\"][\"r2_val_mean\"],\n",
    "        \"cfg\":              slug(cfg),\n",
    "    })\n",
    "\n",
    "blr_cv_table = (pd.DataFrame(rows)\n",
    "                .sort_values([\"cv_rmse_val_mean\", \"cv_rmse_val_sd\", \"model\"])\n",
    "                .reset_index(drop=True))\n",
    "\n",
    "display(blr_cv_table)\n",
    "\n",
    "# BEST residuals on TEST \n",
    "best_pipe = best_overall[\"final_pipe\"]\n",
    "yte_pred_adj = best_pipe.predict(Xte_lin)\n",
    "\n",
    "PL_pred_test = yte_pred_adj + ftr_te\n",
    "resid_test   = yte_pl - PL_pred_test\n",
    "\n",
    "blr_test_df = pd.DataFrame({\n",
    "    \"row_id\":   np.arange(len(df_test), dtype=int),\n",
    "    \"PL_true\":  yte_pl,\n",
    "    \"PL_pred\":  PL_pred_test,\n",
    "    \"resid_db\": resid_test\n",
    "})\n",
    "\n",
    "test_path = f\"{SAVE_DIR}/Reports/residuals__BLR__BEST__test.csv\"\n",
    "blr_test_df.to_csv(test_path, index=False)\n",
    "print(f\"\\n[TEST] Saved best BLR test residuals: {test_path}\")\n",
    "\n",
    "# OOF residuals for BEST (train-only)\n",
    "factory_for_best = next(f for (n, f, g) in blr_specs if n == best_name)\n",
    "\n",
    "y_pred_adj_oof = np.full(len(ytr_adj), np.nan, dtype=float)\n",
    "for tr_idx, val_idx in folds:\n",
    "    pipe = factory_for_best(best_cfg)\n",
    "    with threadpool_limits(limits=1, user_api=\"blas\"):\n",
    "        pipe.fit(Xtr_lin[tr_idx], ytr_adj[tr_idx])\n",
    "    y_pred_adj_oof[val_idx] = pipe.predict(Xtr_lin[val_idx])\n",
    "\n",
    "mask = ~np.isnan(y_pred_adj_oof)\n",
    "\n",
    "PL_pred_oof = y_pred_adj_oof[mask] + ftr_tr[mask]\n",
    "resid_oof   = ytr_pl[mask] - PL_pred_oof\n",
    "\n",
    "blr_oof_df = pd.DataFrame({\n",
    "    \"row_id\":   np.arange(len(df_train), dtype=int)[mask],\n",
    "    \"fold\":     fold_assignments.astype(int)[mask],\n",
    "    \"PL_true\":  ytr_pl[mask],\n",
    "    \"PL_pred\":  PL_pred_oof,\n",
    "    \"resid_db\": resid_oof\n",
    "})\n",
    "\n",
    "oof_path = f\"{SAVE_DIR}/Reports/residuals__BLR__BEST__oof.csv\"\n",
    "blr_oof_df.to_csv(oof_path, index=False)\n",
    "print(f\"\\n[OOF] Saved best BLR OOF residuals: {oof_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f33493d",
   "metadata": {},
   "source": [
    "#### Test metrics table (final fit on full TRAIN, evaluated on held-out TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0edf5ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Test R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLR-Linear (Conjugate)</td>\n",
       "      <td>8.453447</td>\n",
       "      <td>0.798423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLR-Linear (g-prior)</td>\n",
       "      <td>8.453448</td>\n",
       "      <td>0.798423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Test RMSE   Test R2\n",
       "0  BLR-Linear (Conjugate)   8.453447  0.798423\n",
       "1    BLR-Linear (g-prior)   8.453448  0.798423"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_rows = []\n",
    "for res in blr_results:\n",
    "    te = res[\"test\"]\n",
    "    test_rows.append({\n",
    "        \"Model\": res[\"model\"],\n",
    "        \"Test RMSE\": float(te[\"rmse\"]),\n",
    "        \"Test R2\":   float(te[\"r2\"]),\n",
    "    })\n",
    "\n",
    "test_blr_df = pd.DataFrame(test_rows)\n",
    "display(test_blr_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce132f73-97bb-442a-9ccc-12fe882e15c8",
   "metadata": {},
   "source": [
    "#### Coefficients Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "964cc561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Posterior Means (original units) — BLR, linear basis \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLR-Linear (Conjugate)</th>\n",
       "      <th>BLR-Linear (g-prior)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>2.305528</td>\n",
       "      <td>2.305544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z_d</th>\n",
       "      <td>3.866506</td>\n",
       "      <td>3.866504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_walls</th>\n",
       "      <td>6.830244</td>\n",
       "      <td>6.830240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w_walls</th>\n",
       "      <td>1.977092</td>\n",
       "      <td>1.977091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co2</th>\n",
       "      <td>-0.002355</td>\n",
       "      <td>-0.002355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>-0.091712</td>\n",
       "      <td>-0.091712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pm25</th>\n",
       "      <td>-0.095295</td>\n",
       "      <td>-0.095295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pressure</th>\n",
       "      <td>-0.008045</td>\n",
       "      <td>-0.008045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>-0.141028</td>\n",
       "      <td>-0.141028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snr</th>\n",
       "      <td>-2.034426</td>\n",
       "      <td>-2.034425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             BLR-Linear (Conjugate)  BLR-Linear (g-prior)\n",
       "Intercept                  2.305528              2.305544\n",
       "z_d                        3.866506              3.866504\n",
       "c_walls                    6.830244              6.830240\n",
       "w_walls                    1.977092              1.977091\n",
       "co2                       -0.002355             -0.002355\n",
       "humidity                  -0.091712             -0.091712\n",
       "pm25                      -0.095295             -0.095295\n",
       "pressure                  -0.008045             -0.008045\n",
       "temperature               -0.141028             -0.141028\n",
       "snr                       -2.034426             -2.034425"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef_blr_df = pd.concat(\n",
    "    [res[\"coef_tbl\"][\"mean\"].rename(res[\"model\"]) for res in blr_results],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"\\nPosterior Means (original units) — BLR, linear basis \")\n",
    "display(coef_blr_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general101 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
