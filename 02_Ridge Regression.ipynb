{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7adb7f90-216d-4919-9a69-6391c114e634",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "Ridge Regression Model fitting \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "223237b5-83be-4772-b61d-9ad3b2832e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== Core & Data Libraries ==============================\n",
    "import os                                   # File and directory operations\n",
    "import pickle                               # Object serialization\n",
    "import numpy as np                          # Numerical computations\n",
    "import pandas as pd                         # Data manipulation and analysis\n",
    "\n",
    "# ============================== Machine Learning & Stats ===========================\n",
    "from sklearn.model_selection import KFold, train_test_split   # Data splitting, cross-validation\n",
    "from sklearn.metrics import mean_squared_error, r2_score      # Model evaluation metrics\n",
    "from sklearn.linear_model import RidgeCV                      # Ridge regression with CV\n",
    "from sklearn.preprocessing import StandardScaler              # Feature scaling\n",
    "from sklearn.pipeline import make_pipeline                    # Pipeline for scaling and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284990ba-96ba-43ae-a130-d3f476419345",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    " Dataset: Load Saved Splits and Fold Assignments\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c9ab4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training samples: 1209643, Test samples: 302411\n",
      "{np.int64(0): np.int64(241929), np.int64(1): np.int64(241929), np.int64(2): np.int64(241929), np.int64(3): np.int64(241928), np.int64(4): np.int64(241928)}\n",
      "\n",
      "Dataset loaded successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the standardized database directory\n",
    "base_path = '../Extended Parametric Regression Files+Plots.'\n",
    "\n",
    "# Load train and test splits\n",
    "df_train = pd.read_csv(f\"{base_path}/train.csv\")\n",
    "df_test = pd.read_csv(f\"{base_path}/test.csv\")\n",
    "\n",
    "# Extract features and targets\n",
    "feature_names = [\n",
    "    'distance', 'frequency', 'c_walls', 'w_walls', 'co2', 'humidity', \n",
    "    'pm25', 'pressure', 'temperature', 'snr'\n",
    "]\n",
    "X_train = df_train[feature_names].values\n",
    "y_train = df_train['PL'].values\n",
    "X_test = df_test[feature_names].values\n",
    "y_test = df_test['PL'].values\n",
    "\n",
    "# (Should we need 'time' for plotting)\n",
    "time_train = df_train['time'].values\n",
    "time_test = df_test['time'].values\n",
    "\n",
    "# Print number of samples in train and test sets\n",
    "print(f\"\\nTraining samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Load 5-fold assignments (array of fold numbers for each train sample)\n",
    "fold_assignments = np.load(f\"{base_path}/train_folds.npy\")\n",
    "\n",
    "# Print fold distribution\n",
    "unique, counts = np.unique(fold_assignments, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "print('\\nDataset loaded successfully!\\n')\n",
    "\n",
    "# Prepare linearized features and adjusted targets for linear models\n",
    "# Linearization separates the non-linear frequency term and transforms distance term\n",
    "d0 = 1.0\n",
    "\n",
    "# Train\n",
    "log_d_train = np.log10(X_train[:, 0] / d0)\n",
    "offset_train = 20 * np.log10(X_train[:, 1])  # Fixed frequency contribution\n",
    "X_lin_train = np.column_stack((\n",
    "    10 * log_d_train,  # Transformed distance term for path loss exponent\n",
    "    X_train[:, 2:10]   # Remaining linear features\n",
    "))\n",
    "y_train_adj = y_train - offset_train  # Adjust target by subtracting frequency offset\n",
    "\n",
    "# Test\n",
    "log_d_test = np.log10(X_test[:, 0] / d0)\n",
    "offset_test = 20 * np.log10(X_test[:, 1])\n",
    "X_lin_test = np.column_stack((\n",
    "    10 * log_d_test,\n",
    "    X_test[:, 2:10]\n",
    "))\n",
    "y_test_adj = y_test - offset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d8c2e8-0376-4a0b-bb56-52bf1da0865d",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "  Ridge Regression Model\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1158ff32-9b33-4a7b-b2b1-9ff9752e66b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================  Model Function ===================\n",
    "\n",
    "def log_distance_path_loss_with_env_params(x, PL_d0, n, L_c, L_w,\n",
    "                                           a_co2, a_hum, a_pm25,\n",
    "                                           a_pres, a_temp, k_snr):\n",
    "    \"\"\"\n",
    "    Path loss model with environmental parameters.\n",
    "    x: 2D array (10, N), where:\n",
    "       x[0]=distance, x[1]=frequency, x[2]=c_walls, ..., x[9]=snr\n",
    "    \"\"\"\n",
    "    d, frequency, c_walls, w_walls, co2, humidity, pm25, pressure, temperature, snr = x\n",
    "    d0 = 1  # Reference distance\n",
    "    return (PL_d0\n",
    "            + 10 * n * np.log10(d / d0)\n",
    "            + 20 * np.log10(frequency)\n",
    "            + c_walls * L_c\n",
    "            + w_walls * L_w\n",
    "            + a_co2 * co2\n",
    "            + a_hum * humidity\n",
    "            + a_pm25 * pm25\n",
    "            + a_pres * pressure\n",
    "            + a_temp * temperature\n",
    "            + snr * k_snr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e150471-75f7-4a0a-be67-c419f2cc31b4",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    " 5-Fold Cross-Validation on Training Set\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34b07c02-f46d-4d83-9cc8-32992541a2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: RMSE_train=8.1844, RMSE_val=8.1886\n",
      "Fold 2: RMSE_train=8.1860, RMSE_val=8.1820\n",
      "Fold 3: RMSE_train=8.1878, RMSE_val=8.1748\n",
      "Fold 4: RMSE_train=8.1830, RMSE_val=8.1941\n",
      "Fold 5: RMSE_train=8.1848, RMSE_val=8.1868\n",
      "\n",
      "=== Cross-Validation Results on the training set ===\n",
      "RMSE (Train): 8.1852 ± 0.0016\n",
      "RMSE (Val):   8.1853 ± 0.0065\n",
      "R2 (Train):   0.8169 ± 0.0002\n",
      "R2 (Val):     0.8169 ± 0.0006\n"
     ]
    }
   ],
   "source": [
    "# =================== 5-Fold Cross-Validation (Training set only) ===================\n",
    "\n",
    "# Range of alpha values for regularization strength\n",
    "alphas = np.logspace(-6, 6, 200)\n",
    "\n",
    "rmse_train_folds, rmse_val_folds = [], []\n",
    "r2_train_folds, r2_val_folds = [], []\n",
    "cv_coeffs = []\n",
    "\n",
    "for fold_num in range(5):\n",
    "    tr_idx = np.where(fold_assignments != fold_num)[0]\n",
    "    val_idx = np.where(fold_assignments == fold_num)[0]\n",
    "    X_tr = X_lin_train[tr_idx]\n",
    "    y_tr_adj = y_train_adj[tr_idx]\n",
    "    X_val = X_lin_train[val_idx]\n",
    "    y_val_adj = y_train_adj[val_idx]\n",
    "    offset_tr = offset_train[tr_idx]\n",
    "    offset_val = offset_train[val_idx]\n",
    "\n",
    "    # Pipeline for scaling (fit on train) and RidgeCV (inner CV on scaled data)\n",
    "    pipeline = make_pipeline(StandardScaler(), RidgeCV(alphas=alphas, cv=5, scoring='neg_mean_squared_error'))\n",
    "    pipeline.fit(X_tr, y_tr_adj)\n",
    "\n",
    "    # Extract Ridge model and scaler for coefficient access\n",
    "    scaler = pipeline.named_steps['standardscaler']\n",
    "    ridge_cv = pipeline.named_steps['ridgecv']\n",
    "\n",
    "    # Back-transform coefficients to original scale for interpretability\n",
    "    coef_scaled = ridge_cv.coef_\n",
    "    intercept_scaled = ridge_cv.intercept_\n",
    "    coef_unscaled = coef_scaled / scaler.scale_\n",
    "    intercept_unscaled = intercept_scaled - np.sum((coef_scaled * scaler.mean_) / scaler.scale_)\n",
    "    cv_coeffs.append(np.concatenate(([intercept_unscaled], coef_unscaled)))\n",
    "\n",
    "    # Training fold metrics (reconstruct full predictions)\n",
    "    y_tr_pred_adj = pipeline.predict(X_tr)\n",
    "    y_tr_pred = y_tr_pred_adj + offset_tr\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train[tr_idx], y_tr_pred))\n",
    "    r2_train = r2_score(y_train[tr_idx], y_tr_pred)\n",
    "    rmse_train_folds.append(rmse_train)\n",
    "    r2_train_folds.append(r2_train)\n",
    "\n",
    "    # Validation fold metrics\n",
    "    y_val_pred_adj = pipeline.predict(X_val)\n",
    "    y_val_pred = y_val_pred_adj + offset_val\n",
    "    rmse_val = np.sqrt(mean_squared_error(y_train[val_idx], y_val_pred))\n",
    "    r2_val = r2_score(y_train[val_idx], y_val_pred)\n",
    "    rmse_val_folds.append(rmse_val)\n",
    "    r2_val_folds.append(r2_val)\n",
    "\n",
    "    print(f\"Fold {fold_num+1}: RMSE_train={rmse_train:.4f}, RMSE_val={rmse_val:.4f}\")\n",
    "\n",
    "print(\"\\n=== Cross-Validation Results on the training set ===\")\n",
    "print(f\"RMSE (Train): {np.mean(rmse_train_folds):.4f} ± {np.std(rmse_train_folds):.4f}\")\n",
    "print(f\"RMSE (Val):   {np.mean(rmse_val_folds):.4f} ± {np.std(rmse_val_folds):.4f}\")\n",
    "print(f\"R2 (Train):   {np.mean(r2_train_folds):.4f} ± {np.std(r2_train_folds):.4f}\")\n",
    "print(f\"R2 (Val):     {np.mean(r2_val_folds):.4f} ± {np.std(r2_val_folds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b81cc8-35ea-4d5a-9e4f-7c00d359a12b",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    " Retrain Final Model on All Training Data\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98675c50-c12b-497d-9f5c-7747bb124163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Ridge model coefficients saved to Models/ridge_final_coeffs.pkl\n",
      "\n",
      "=== Model Coefficients ===\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Final Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PL(d0) [dB]</td>\n",
       "      <td>2.286467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Path loss exponent (n)</td>\n",
       "      <td>3.939079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brick Wall Loss (L_c) [dB]</td>\n",
       "      <td>6.670053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wood Wall Loss (L_w) [dB]</td>\n",
       "      <td>1.923339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CO2 coef. (a_co2) [dB/unit]</td>\n",
       "      <td>-0.002338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Humidity coef. (a_hum) [dB/%]</td>\n",
       "      <td>-0.086681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PM2.5 coef. (a_pm25) [dB/µg/m³]</td>\n",
       "      <td>-0.088268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pressure coef. (a_pres) [dB/hPa]</td>\n",
       "      <td>-0.008839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Temp. coef. (a_temp) [dB/°C]</td>\n",
       "      <td>-0.153558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNR scaling (k_snr)</td>\n",
       "      <td>-2.067426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Parameter  Final Model\n",
       "0                       PL(d0) [dB]     2.286467\n",
       "1            Path loss exponent (n)     3.939079\n",
       "2        Brick Wall Loss (L_c) [dB]     6.670053\n",
       "3         Wood Wall Loss (L_w) [dB]     1.923339\n",
       "4       CO2 coef. (a_co2) [dB/unit]    -0.002338\n",
       "5     Humidity coef. (a_hum) [dB/%]    -0.086681\n",
       "6   PM2.5 coef. (a_pm25) [dB/µg/m³]    -0.088268\n",
       "7  Pressure coef. (a_pres) [dB/hPa]    -0.008839\n",
       "8      Temp. coef. (a_temp) [dB/°C]    -0.153558\n",
       "9               SNR scaling (k_snr)    -2.067426"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =================== Final Model Training (All Training Data) ===================\n",
    "\n",
    "# Refit on full training data with pipeline for scaling and CV for alpha selection\n",
    "alphas = np.logspace(-6, 6, 100)\n",
    "pipeline = make_pipeline(StandardScaler(), RidgeCV(alphas=alphas, cv=5, scoring='neg_mean_squared_error'))\n",
    "pipeline.fit(X_lin_train, y_train_adj)\n",
    "\n",
    "# Extract scaler and ridge for back-transformation\n",
    "scaler = pipeline.named_steps['standardscaler']\n",
    "ridge_cv = pipeline.named_steps['ridgecv']\n",
    "\n",
    "# Back-transform coefficients to original scale\n",
    "coef_scaled = ridge_cv.coef_\n",
    "intercept_scaled = ridge_cv.intercept_\n",
    "coef_unscaled = coef_scaled / scaler.scale_\n",
    "intercept_unscaled = intercept_scaled - np.sum((coef_scaled * scaler.mean_) / scaler.scale_)\n",
    "\n",
    "final_coeffs = np.concatenate(([intercept_unscaled], coef_unscaled))\n",
    "\n",
    "# ========== Save coefficients   ==========\n",
    "os.makedirs('Models', exist_ok=True) # Create 'models' folder if it doesn't exist\n",
    "with open('Models/ridge_final_coeffs.pkl', 'wb') as f:\n",
    "    pickle.dump(final_coeffs, f)\n",
    "print(\"\\nFinal Ridge model coefficients saved to Models/ridge_final_coeffs.pkl\")\n",
    "\n",
    "# ========== Unpack and display table ==========\n",
    "PL_d0, n, L_c, L_w, a_co2, a_hum, a_pm25, a_pres, a_temp, k_snr = final_coeffs\n",
    "\n",
    "params_final = {\n",
    "    'PL(d0) [dB]': PL_d0,\n",
    "    'Path loss exponent (n)': n,\n",
    "    'Brick Wall Loss (L_c) [dB]': L_c,\n",
    "    'Wood Wall Loss (L_w) [dB]': L_w,\n",
    "    'CO2 coef. (a_co2) [dB/unit]': a_co2,\n",
    "    'Humidity coef. (a_hum) [dB/%]': a_hum,\n",
    "    'PM2.5 coef. (a_pm25) [dB/µg/m³]': a_pm25,\n",
    "    'Pressure coef. (a_pres) [dB/hPa]': a_pres,\n",
    "    'Temp. coef. (a_temp) [dB/°C]': a_temp,\n",
    "    'SNR scaling (k_snr)': k_snr\n",
    "}\n",
    "\n",
    "params_final_df = pd.DataFrame({\n",
    "    'Parameter': list(params_final.keys()),\n",
    "    'Final Model': list(params_final.values())\n",
    "})\n",
    "\n",
    "print(\"\\n=== Model Coefficients ===\\n\")\n",
    "display(params_final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69d42827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected alpha: 4.641588833612782\n"
     ]
    }
   ],
   "source": [
    "print(f\"Selected alpha: {ridge_cv.alpha_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a8179-02b3-4a59-aebd-293c4aa3a837",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    " Final Evaluation on Test Set\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c256c6e5-2299-4a93-8b79-7e7665bd71b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 54 features, but StandardScaler is expecting 9 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# =================== Final Evaluation (Test Set) ===================\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Predict on test set and reconstruct full predictions\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m y_test_pred_adj \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_lin_test_poly\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m y_test_pred_adj \u001b[38;5;241m+\u001b[39m offset_test\n\u001b[0;32m      7\u001b[0m rmse_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(y_test, y_test_pred))\n",
      "File \u001b[1;32mc:\\Users\\nahsh\\anaconda3\\envs\\general_env\\lib\\site-packages\\sklearn\\pipeline.py:787\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 787\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    790\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nahsh\\anaconda3\\envs\\general_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\nahsh\\anaconda3\\envs\\general_env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1062\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1059\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1061\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1062\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1071\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mc:\\Users\\nahsh\\anaconda3\\envs\\general_env\\lib\\site-packages\\sklearn\\utils\\validation.py:2965\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 2965\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\nahsh\\anaconda3\\envs\\general_env\\lib\\site-packages\\sklearn\\utils\\validation.py:2829\u001b[0m, in \u001b[0;36m_check_n_features\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m-> 2829\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2830\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2831\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2832\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 54 features, but StandardScaler is expecting 9 features as input."
     ]
    }
   ],
   "source": [
    "# =================== Final Evaluation (Test Set) ===================\n",
    "\n",
    "# Predict on test set and reconstruct full predictions\n",
    "y_test_pred_adj = pipeline.predict(X_lin_test_poly)\n",
    "y_test_pred = y_test_pred_adj + offset_test\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nTest RMSE: {rmse_test:.4f}\")\n",
    "print(f\"Test R2:   {r2_test:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (general_env)",
   "language": "python",
   "name": "general_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
