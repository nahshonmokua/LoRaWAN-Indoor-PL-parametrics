{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7adb7f90-216d-4919-9a69-6391c114e634",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    " Polynomial Regresiion Fitiing\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "223237b5-83be-4772-b61d-9ad3b2832e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== Core & Data Libraries ==============================\n",
    "import os                                   # File and directory operations\n",
    "import pickle                               # Object serialization\n",
    "import numpy as np                          # Numerical computations\n",
    "import pandas as pd                         # Data manipulation and analysis\n",
    "\n",
    "# ============================== Machine Learning & Stats ===========================\n",
    "from sklearn.metrics import mean_squared_error, r2_score      # Model evaluation metrics\n",
    "from sklearn.linear_model import RidgeCV                      # Ridge for regularization with poly\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures  # Feature scaling and poly\n",
    "from sklearn.pipeline import make_pipeline                    # Pipeline for scaling and model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284990ba-96ba-43ae-a130-d3f476419345",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    " Dataset: Load Saved Splits and Fold Assignments\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7189f06e-c7e4-4deb-ab20-d3771dea7204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training samples: 1209643, Test samples: 302411\n",
      "{np.int64(0): np.int64(241929), np.int64(1): np.int64(241929), np.int64(2): np.int64(241929), np.int64(3): np.int64(241928), np.int64(4): np.int64(241928)}\n",
      "\n",
      "Dataset loaded successfully!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the standardized database directory\n",
    "base_path = '../Extended Parametric Regression Files+Plots.'\n",
    "\n",
    "# Load train and test splits\n",
    "df_train = pd.read_csv(f\"{base_path}/train.csv\")\n",
    "df_test = pd.read_csv(f\"{base_path}/test.csv\")\n",
    "\n",
    "# Extract features and targets\n",
    "feature_names = [\n",
    "    'distance', 'frequency', 'c_walls', 'w_walls', 'co2', 'humidity', \n",
    "    'pm25', 'pressure', 'temperature', 'snr'\n",
    "]\n",
    "X_train = df_train[feature_names].values\n",
    "y_train = df_train['PL'].values\n",
    "X_test = df_test[feature_names].values\n",
    "y_test = df_test['PL'].values\n",
    "\n",
    "# (Should we need 'time' for plotting)\n",
    "time_train = df_train['time'].values\n",
    "time_test = df_test['time'].values\n",
    "\n",
    "# Print number of samples in train and test sets\n",
    "print(f\"\\nTraining samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Load 5-fold assignments (array of fold numbers for each train sample)\n",
    "fold_assignments = np.load(f\"{base_path}/train_folds.npy\")\n",
    "\n",
    "# Print fold distribution\n",
    "unique, counts = np.unique(fold_assignments, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "print('\\nDataset loaded successfully!\\n')\n",
    "\n",
    "# Prepare linearized features and adjusted targets for linear models\n",
    "# Linearization separates the non-linear frequency term and transforms distance term\n",
    "d0 = 1.0\n",
    "\n",
    "# Train\n",
    "log_d_train = np.log10(X_train[:, 0] / d0)\n",
    "offset_train = 20 * np.log10(X_train[:, 1])  # Fixed frequency contribution\n",
    "X_lin_train = np.column_stack((\n",
    "    10 * log_d_train,  # Transformed distance term for path loss exponent\n",
    "    X_train[:, 2:10]   # Remaining linear features\n",
    "))\n",
    "y_train_adj = y_train - offset_train  # Adjust target by subtracting frequency offset\n",
    "\n",
    "# Test\n",
    "log_d_test = np.log10(X_test[:, 0] / d0)\n",
    "offset_test = 20 * np.log10(X_test[:, 1])\n",
    "X_lin_test = np.column_stack((\n",
    "    10 * log_d_test,\n",
    "    X_test[:, 2:10]\n",
    "))\n",
    "y_test_adj = y_test - offset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d8c2e8-0376-4a0b-bb56-52bf1da0865d",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    "  Polynomial Regression Model\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1158ff32-9b33-4a7b-b2b1-9ff9752e66b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== Model Function ===================\n",
    "\n",
    "# Retained for reference; not used directly in fitting but defines the full model\n",
    "def log_distance_path_loss_with_env_params(x, PL_d0, n, L_c, L_w,\n",
    "                                           a_co2, a_hum, a_pm25,\n",
    "                                           a_pres, a_temp, k_snr):\n",
    "    \"\"\"\n",
    "    Path loss model with environmental parameters.\n",
    "    x: 2D array (10, N), where:\n",
    "       x[0]=distance, x[1]=frequency, x[2]=c_walls, ..., x[9]=snr\n",
    "    \"\"\"\n",
    "    d, frequency, c_walls, w_walls, co2, humidity, pm25, pressure, temperature, snr = x\n",
    "    d0 = 1  # Reference distance\n",
    "    return (PL_d0\n",
    "            + 10 * n * np.log10(d / d0)\n",
    "            + 20 * np.log10(frequency)\n",
    "            + c_walls * L_c\n",
    "            + w_walls * L_w\n",
    "            + a_co2 * co2\n",
    "            + a_hum * humidity\n",
    "            + a_pm25 * pm25\n",
    "            + a_pres * pressure\n",
    "            + a_temp * temperature\n",
    "            + snr * k_snr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e150471-75f7-4a0a-be67-c419f2cc31b4",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    " 5-Fold Cross-Validation on Training Set\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34b07c02-f46d-4d83-9cc8-32992541a2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: RMSE_train=6.9840, RMSE_val=7.0129\n",
      "Fold 2: RMSE_train=6.9911, RMSE_val=6.9845\n",
      "Fold 3: RMSE_train=6.9937, RMSE_val=6.9741\n",
      "Fold 4: RMSE_train=6.9904, RMSE_val=6.9873\n",
      "Fold 5: RMSE_train=6.9887, RMSE_val=6.9936\n",
      "\n",
      "=== Cross-Validation Results on the training set ===\n",
      "RMSE (Train): 6.9896 ± 0.0032\n",
      "RMSE (Val):   6.9905 ± 0.0129\n",
      "R2 (Train):   0.8665 ± 0.0001\n",
      "R2 (Val):     0.8664 ± 0.0004\n"
     ]
    }
   ],
   "source": [
    "# =================== 5-Fold Cross-Validation (Training set only) ===================\n",
    "\n",
    "# Range of alpha values for regularization strength\n",
    "alphas = np.logspace(-6, 6, 100)\n",
    "\n",
    "rmse_train_folds, rmse_val_folds = [], []\n",
    "r2_train_folds, r2_val_folds = [], []\n",
    "cv_coeffs = []\n",
    "\n",
    "for fold_num in range(5):\n",
    "    tr_idx = np.where(fold_assignments != fold_num)[0]\n",
    "    val_idx = np.where(fold_assignments == fold_num)[0]\n",
    "    X_tr = X_lin_train[tr_idx]\n",
    "    y_tr_adj = y_train_adj[tr_idx]\n",
    "    X_val = X_lin_train[val_idx]\n",
    "    y_val_adj = y_train_adj[val_idx]\n",
    "    offset_tr = offset_train[tr_idx]\n",
    "    offset_val = offset_train[val_idx]\n",
    "\n",
    "    # Pipeline for scaling, polynomial features, and RidgeCV\n",
    "    pipeline = make_pipeline(StandardScaler(), PolynomialFeatures(degree=2), RidgeCV(alphas=alphas, cv=5, scoring='neg_mean_squared_error'))\n",
    "    pipeline.fit(X_tr, y_tr_adj)\n",
    "\n",
    "    # For coeffs, extract but note they are expanded and in scaled space (no simple back-transform for poly)\n",
    "    # We append the full coefficients for CV tracking\n",
    "    ridge_cv = pipeline.named_steps['ridgecv']\n",
    "    cv_coeffs.append(np.concatenate(([ridge_cv.intercept_], ridge_cv.coef_)))\n",
    "\n",
    "    # Training fold metrics (reconstruct full predictions)\n",
    "    y_tr_pred_adj = pipeline.predict(X_tr)\n",
    "    y_tr_pred = y_tr_pred_adj + offset_tr\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train[tr_idx], y_tr_pred))\n",
    "    r2_train = r2_score(y_train[tr_idx], y_tr_pred)\n",
    "    rmse_train_folds.append(rmse_train)\n",
    "    r2_train_folds.append(r2_train)\n",
    "\n",
    "    # Validation fold metrics\n",
    "    y_val_pred_adj = pipeline.predict(X_val)\n",
    "    y_val_pred = y_val_pred_adj + offset_val\n",
    "    rmse_val = np.sqrt(mean_squared_error(y_train[val_idx], y_val_pred))\n",
    "    r2_val = r2_score(y_train[val_idx], y_val_pred)\n",
    "    rmse_val_folds.append(rmse_val)\n",
    "    r2_val_folds.append(r2_val)\n",
    "\n",
    "    print(f\"Fold {fold_num+1}: RMSE_train={rmse_train:.4f}, RMSE_val={rmse_val:.4f}\")\n",
    "\n",
    "print(\"\\n=== Cross-Validation Results on the training set ===\")\n",
    "print(f\"RMSE (Train): {np.mean(rmse_train_folds):.4f} ± {np.std(rmse_train_folds):.4f}\")\n",
    "print(f\"RMSE (Val):   {np.mean(rmse_val_folds):.4f} ± {np.std(rmse_val_folds):.4f}\")\n",
    "print(f\"R2 (Train):   {np.mean(r2_train_folds):.4f} ± {np.std(r2_train_folds):.4f}\")\n",
    "print(f\"R2 (Val):     {np.mean(r2_val_folds):.4f} ± {np.std(r2_val_folds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b81cc8-35ea-4d5a-9e4f-7c00d359a12b",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    " Retrain Final Model on All Training Data\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98675c50-c12b-497d-9f5c-7747bb124163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Polynomial model coefficients saved to Models/poly_final_coeffs.pkl\n"
     ]
    }
   ],
   "source": [
    "# =================== Final Model Training (All Training Data) ===================\n",
    "\n",
    "# Use the same pipeline as in CV for consistency: full poly on all features with scaling\n",
    "alphas = np.logspace(-6, 6, 100)\n",
    "pipeline = make_pipeline(StandardScaler(), PolynomialFeatures(degree=2), RidgeCV(alphas=alphas, cv=5, scoring='neg_mean_squared_error'))\n",
    "pipeline.fit(X_lin_train, y_train_adj)\n",
    "\n",
    "# Extract the fitted RidgeCV for coefficient access (note: coeffs are in scaled/poly space, no simple unpacking)\n",
    "ridge_cv = pipeline.named_steps['ridgecv']\n",
    "final_coeffs = np.concatenate(([ridge_cv.intercept_], ridge_cv.coef_))\n",
    "\n",
    "# ========== Save coefficients   ==========\n",
    "os.makedirs('Models', exist_ok=True) # Create 'models' folder if it doesn't exist\n",
    "with open('Models/poly_final_coeffs.pkl', 'wb') as f:\n",
    "    pickle.dump(final_coeffs, f)\n",
    "print(\"\\nFinal Polynomial model coefficients saved to Models/poly_final_coeffs.pkl\")\n",
    "# No simple unpacking/display since coeffs are expanded (56 terms) and scaled; \n",
    "# for interpretability, we could consider partial polynomial instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a8179-02b3-4a59-aebd-293c4aa3a837",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: left;\">\n",
    " Final Evaluation on Test Set\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c256c6e5-2299-4a93-8b79-7e7665bd71b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test RMSE: 7.0069\n",
      "Test R2:   0.8659\n"
     ]
    }
   ],
   "source": [
    "# =================== Final Evaluation (Test Set) ===================\n",
    "\n",
    "# Predict on test set and reconstruct full predictions\n",
    "y_test_pred_adj = pipeline.predict(X_lin_test)\n",
    "y_test_pred = y_test_pred_adj + offset_test\n",
    "\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nTest RMSE: {rmse_test:.4f}\")\n",
    "print(f\"Test R2:   {r2_test:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (general_env)",
   "language": "python",
   "name": "general_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
